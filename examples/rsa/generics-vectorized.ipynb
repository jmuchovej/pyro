{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 287,
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 288,
            "source": [
                "import argparse\n",
                "import collections\n",
                "import numbers\n",
                "\n",
                "import torch\n",
                "from search_inference import HashingMarginal, Search, memoize\n",
                "\n",
                "import pyro\n",
                "import pyro.distributions as dist\n",
                "import pyro.poutine as poutine\n",
                "from pyro.infer import config_enumerate, TraceEnum_ELBO\n",
                "from pyro.ops.indexing import Vindex\n",
                "\n",
                "torch.set_default_dtype(torch.float64)  # double precision for numerical stability\n",
                "torch.manual_seed(42)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<torch._C.Generator at 0x7f8d3c5e2e70>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 288
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 307,
            "source": [
                "from vectorized_search import VectoredSearch, VectoredHashingMarginal\n",
                "\n",
                "def Marginal(fn):\n",
                "    marginal = VectoredHashingMarginal(VectoredSearch(config_enumerate(fn)))\n",
                "    return memoize(lambda *args: marginal.run(*args)))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 290,
            "source": [
                "utterances = [\n",
                "    \"generic is true\", \"generic is false\",\n",
                "    \"mu\", \"some\", \"most\", \"all\",\n",
                "]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 308,
            "source": [
                "Params = collections.namedtuple(\"Params\", [\"theta\", \"gamma\", \"delta\"])\n",
                "\n",
                "beta_bins = torch.tensor([0., 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99])\n",
                "\n",
                "@Marginal\n",
                "def structured_prior(params: Params) -> torch.Tensor:\n",
                "    # computing the Beta pdf for discretized bins above for enumerated Search\n",
                "    shape_alpha = params.gamma * params.delta - 1\n",
                "    shape_beta  = (1. - params.gamma) * params.delta - 1\n",
                "    discrete_bins = (beta_bins ** shape_alpha) * ((1. - beta_bins) ** shape_beta) * params.theta\n",
                "    discrete_bins[0] = (1 - params.theta)\n",
                "    idx = pyro.sample(\"bin\", dist.Categorical(probs=discrete_bins / discrete_bins.sum()))\n",
                "\n",
                "    return beta_bins[idx]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 309,
            "source": [
                "wings_prior_params = Params(theta=0.5, gamma=0.99, delta=10.0)\n",
                "wings_prior = structured_prior(wings_prior_params)\n",
                "\n",
                "for el in wings_prior.enumerate_support():\n",
                "    print(el.item(), wings_prior.log_prob(el).exp().item())"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0.0 0.015988904498871442\n",
                        "0.01 2.2204460492503185e-16\n",
                        "0.1 2.213097002755768e-11\n",
                        "0.2 1.175451410947732e-08\n",
                        "0.3 4.893387852027631e-07\n",
                        "0.4 7.274723747978211e-06\n",
                        "0.5 6.245665819871659e-05\n",
                        "0.6 0.00038682171379413966\n",
                        "0.7 0.00197597813839096\n",
                        "0.8 0.009340983321304765\n",
                        "0.9 0.0497252576984154\n",
                        "0.99 0.922511822131846\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 293,
            "source": [
                "def utterance_prior() -> torch.Tensor:\n",
                "    utts = torch.arange(0, len(utterances), 1)\n",
                "    probs = torch.ones_like(utts) / len(utts)\n",
                "    idx = pyro.sample(\"utterance\", dist.Categorical(probs=probs))\n",
                "    return utts[idx]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 294,
            "source": [
                "def threshold_prior() -> torch.Tensor:\n",
                "    bins = torch.arange(0.0, 1.0, 0.1)\n",
                "    idx = pyro.sample(\"threshold\", dist.Categorical(logits=torch.zeros_like(bins)))\n",
                "    return bins[idx]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 295,
            "source": [
                "def meaning(utterance: torch.Tensor, state: torch.Tensor, threshold: torch.Tensor) -> torch.Tensor:\n",
                "    possible_evals = {\n",
                "        \"as_genT\": (state > threshold),\n",
                "        \"as_genF\": (state <= threshold),\n",
                "        \"is_mu\"  : torch.full_like(state, True, dtype=bool),\n",
                "        \"is_some\": (state > 0),\n",
                "        \"is_most\": (state >= 0.5),\n",
                "        \"is_all\" : (state >= 0.99),\n",
                "        \"as_num\" : (state == utterance),\n",
                "        \"default\": torch.full_like(state, True, dtype=bool),\n",
                "    }\n",
                "\n",
                "    meanings = torch.stack(list(possible_evals.values()))\n",
                "\n",
                "    while utterance.ndim < meanings.ndim:  # expand utterance to be used as an indexer\n",
                "        utterance = utterance[None]\n",
                "\n",
                "    return torch.gather(meanings, dim=0, index=utterance.long()).float().squeeze()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Listener 0"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 314,
            "source": [
                "@Marginal\n",
                "def listener0(utterances: torch.Tensor, thresholds: torch.Tensor, prior: HashingMarginal) -> torch.Tensor:\n",
                "    state = pyro.sample(f\"state\", prior)\n",
                "    means = meaning(utterances, state, thresholds)\n",
                "    pyro.factor(f\"listener0-true\", torch.where(means == 1., 0., -99_999.))\n",
                "    return state"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 315,
            "source": [
                "wings_posterior = listener0(torch.tensor([1]), torch.tensor([0.1]), wings_prior)\n",
                "for el in wings_posterior.enumerate_support():\n",
                "    print(el, wings_posterior.log_prob(el).exp().item())\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor(0.9900) 1.0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 301,
            "source": [
                "wings_posterior.trace_dist.exec_traces[0].nodes"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "OrderedDict([('_INPUT',\n",
                            "              {'name': '_INPUT',\n",
                            "               'type': 'args',\n",
                            "               'args': (tensor([1]), tensor([0.1000])),\n",
                            "               'kwargs': {}}),\n",
                            "             ('state',\n",
                            "              {'type': 'sample',\n",
                            "               'name': 'state',\n",
                            "               'fn': <vectorized_search.VectoredHashingMarginal at 0x7f8d24a94d90>,\n",
                            "               'is_observed': False,\n",
                            "               'args': (),\n",
                            "               'kwargs': {},\n",
                            "               'value': tensor([0.9000]),\n",
                            "               'infer': {'enumerate': 'parallel', 'expand': True},\n",
                            "               'scale': 1.0,\n",
                            "               'mask': None,\n",
                            "               'cond_indep_stack': (),\n",
                            "               'done': True,\n",
                            "               'stop': True,\n",
                            "               'continuation': None,\n",
                            "               'unscaled_log_prob': tensor([-3.0012]),\n",
                            "               'log_prob': tensor([-3.0012]),\n",
                            "               'log_prob_sum': tensor(-3.0012)}),\n",
                            "             ('listener0-true',\n",
                            "              {'type': 'sample',\n",
                            "               'name': 'listener0-true',\n",
                            "               'fn': Unit(log_factor: -99999.0),\n",
                            "               'is_observed': True,\n",
                            "               'args': (),\n",
                            "               'kwargs': {},\n",
                            "               'value': tensor([]),\n",
                            "               'infer': {'is_auxiliary': True, '_dim_to_id': {}},\n",
                            "               'scale': 1.0,\n",
                            "               'mask': None,\n",
                            "               'cond_indep_stack': (),\n",
                            "               'done': True,\n",
                            "               'stop': True,\n",
                            "               'continuation': None,\n",
                            "               'unscaled_log_prob': tensor(-99999.),\n",
                            "               'log_prob': tensor(-99999.),\n",
                            "               'log_prob_sum': tensor(-99999.)}),\n",
                            "             ('_RETURN',\n",
                            "              {'name': '_RETURN',\n",
                            "               'type': 'return',\n",
                            "               'value': tensor([0.9000])})])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 301
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.10 64-bit ('pyro': conda)"
        },
        "interpreter": {
            "hash": "9bc28b369b6d70ba89e337d74d0d547816f4fa8c93eafedc4eb46222a9da357b"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}